# -*- coding: utf-8 -*-
"""ML_final_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UpTGf0j4DdzyhzCe5ytKgtarituZqoNu

# Data Preprocessing
"""

from google.colab import drive
drive.mount('/content/drive')

# Install necessary libraries
!pip install pandas -q
!pip install matplotlib -q
!pip install seaborn -q
!pip install scikit-learn -q
!pip install scikit-learn -q
!pip install tensorflow -q
!pip install keras -q

# Importing data manipulation and visualization libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Importing machine learning and preprocessing libraries
from sklearn.model_selection import train_test_split  # For splitting datasets
from sklearn.preprocessing import StandardScaler   # For scaling data
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix  # For evaluation metrics
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV

# Importing essential libraries
import tensorflow as tf               # Core deep learning framework
from tensorflow import keras           # High-level API for building neural networks
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv1D, Flatten, Dropout  # Import specific layers
from tensorflow.keras.callbacks import EarlyStopping

# Load the dataset
hdf = pd.read_csv('/content/drive/MyDrive/Final_project/heart.csv')

# Check the shape of the dataset (rows, columns)
print(f"Shape:\n", hdf.shape)

#Check the columns
print(f"Column Names:\n", hdf.columns)

# Preview the first 4 rows of the dataset
print(hdf.head(4))

# Check for basic info like data types and missing values
print(f"Basic Info of Dataset:\n",hdf.info())

# Summary statistics for numerical columns
print(hdf.describe())

"""**Dropping Unnecessary Based on our analysis**"""

# Drop unnecessary columns
hdf = hdf.drop(['fbs'],axis=1)

# Verify the columns after dropping
print("Columns after dropping:", hdf.columns)

"""**Check for Missing Values : Handling Missing Values**"""

# Checking for missing values
missing_data=hdf.isnull().sum()
print("Missing values in each column:\n", missing_data)

"""# Data Visualizing"""

# Plot 1: target Distribution
# The distribution will show how many patients fall into each category (disease present or absent)
sns.histplot(hdf['target'],kde=True,)
plt.title('Target_distribution')
plt.savefig('target Distribution.jpg', dpi=300)
plt.show()


# plot 2: chol rate by age
plt.figure(figsize = (10,6))
sns.barplot(data=hdf,x= 'age',y='chol',ci=None,hue='age')
plt.title('Chol_rate_by_age')
plt.savefig('Chol_rate_by_age.jpg', dpi=300)
plt.show()

# plot 3:chol by gender 1 is male 0 is female
sns.boxplot(data=hdf,x= 'sex',y='chol',hue='sex')
plt.title('Chol by gender')
plt.savefig('chol by gender.jpg', dpi=300)
plt.show()


# plot 4: patients by age
sns.barplot(data=hdf , x='sex', y='target',ci=None,hue='sex')
plt.title('Patients by Gender')
plt.savefig('patients by age.jpg', dpi=300)
plt.show()

"""# correlation"""

# plot 5:Correlation Analysis
corr = hdf.corr()
plt.figure(figsize=(12,10))
sns.heatmap(data=corr, annot=True, cmap='coolwarm', linewidths=0.5)
plt.savefig('correlation.jpg', dpi=300)
plt.show()

"""# Models_Training

**Data for Model Training**
Feature Scaling Scale the numerical features to ensure uniformity in range and distribution across all features.
"""

# Columns to Scale: Based on dataset, age, trestbps, chol, thalach and oldpeak
# are suitable for scaling because they are continuous
# and have varying units and ranges.




# Separate features (X) and target (y)
X = hdf.drop('target', axis=1)
y = hdf['target']

# Split the data into training (80%) and testing (20%) sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


#  Identify columns to scale
columns_to_scale = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']

# Initialize the scaler
scaler = StandardScaler()

# Fit the scaler only on the training data and transform the training data
X_train[columns_to_scale] = scaler.fit_transform(X_train[columns_to_scale])

# Use the same transformation on the test data (do not fit again)
X_test[columns_to_scale] = scaler.transform(X_test[columns_to_scale])



# Check the shapes of the training and testing sets
print("\nX_train shape:", X_train.shape)
print("X_test shape:", X_test.shape)
print("y_train shape:", y_train.shape)
print("y_test shape:", y_test.shape)

"""**1. Logistic Regression Hyperparameter Tuning**
Common Hyperparameters:


*  C: Inverse of regularization strength
* solver: Algorithm to use in optimization.


"""

# Define the parameter grid for Logistic Regression
param_grid_logreg = {
    'C': [0.0001, 0.001, 0.01, 0.1, 1,  50, 100, 1000],  # Regularization strength
    'solver': ['saga', 'lbfgs', 'newton-cg']  # Optimization algorithms saga best for  larger datasets
}

# Initialize the GridSearchCV for Logistic Regression
grid_logreg = GridSearchCV(LogisticRegression(), param_grid_logreg, cv=5)

# Train the model using Grid Search
grid_logreg.fit(X_train, y_train)

# Best parameters from Grid Search
print("Best parameters for Logistic Regression:", grid_logreg.best_params_)

# Evaluate the model with the best parameters
best_logreg = grid_logreg.best_estimator_
y_pred_logreg = best_logreg.predict(X_test)

# Accuracy
logreg_accuracy = accuracy_score(y_test, y_pred_logreg) * 100
print("\nLogistic Regression Accuracy after tuning: {:.2f}%".format(logreg_accuracy))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred_logreg)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.title(f'Confusion Matrix for logreg')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

# Classification Report
logreg_cr = classification_report(y_test, y_pred_logreg, output_dict=True)
logreg_cr_df = pd.DataFrame(logreg_cr).transpose()  # Convert to DataFrame
print("\nClassification Report:\n")
display(logreg_cr_df)

"""**2. SVM Hyperparameter Tuning**
Common Hyperparameters:

* C: Regularization strength.
* gamma: Kernel coefficient.
* kernel: Type of kernel to use ('linear', 'rbf').
"""

# Define the parameter grid for SVM
param_grid_svm = {
    'C': [20,25,50,100],
    'kernel': ['linear', 'rbf'],
    'gamma': [1,15, 20,25]
}


# Initialize the GridSearchCV for SVM
grid_svm = GridSearchCV(SVC(), param_grid_svm, cv=5)

# Train the model using Grid Search
grid_svm.fit(X_train, y_train)

# Best parameters from Grid Search
print("Best parameters for SVM:", grid_svm.best_params_)

# Evaluate the model with the best parameters
best_svm = grid_svm.best_estimator_
y_pred_svm = best_svm.predict(X_test)



# Accuracy
svm_accuracy = accuracy_score(y_test, y_pred_svm) * 100
print("SVM Accuracy after tuning: {:.2f}%".format(svm_accuracy))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred_svm)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.title(f'Confusion Matrix for Svm')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

# Classification Report
svm_cr = classification_report(y_test, y_pred_svm, output_dict=True)
svm_cr_df = pd.DataFrame(svm_cr).transpose()  # Convert to DataFrame
print("\nClassification Report:\n")
display(svm_cr_df)

"""**3. Decision Tree Hyperparameter Tuning**
Common Hyperparameters:
* max_depth: Maximum depth of the tree.
* min_samples_split
"""

# Define the parameter grid for Decision Tree
param_grid_dt = {
    'max_depth': [5, 10, 20, 25, 30, 40, 50],
    'min_samples_split': [ 5, 10, 15, 20, 30, 50]
}


# Initialize the GridSearchCV for Decision Tree
grid_dt = GridSearchCV(DecisionTreeClassifier(), param_grid_dt, cv=5)

# Train the model using Grid Search
grid_dt.fit(X_train, y_train)

# Best parameters from Grid Search
print("Best parameters for Decision Tree:", grid_dt.best_params_)

# Evaluate the model with the best parameters
best_dt = grid_dt.best_estimator_
y_pred_dt = best_dt.predict(X_test)

# Accuracy
dt_accuracy = accuracy_score(y_test, y_pred_dt) * 100
print("Decision Tree Accuracy after tuning: {:.2f}%".format(dt_accuracy))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred_dt)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.title(f'Confusion Matrix for Decision Tree')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

# Classification Report
dt_cr = classification_report(y_test, y_pred_dt, output_dict=True)
dt_cr_df = pd.DataFrame(dt_cr).transpose()  # Convert to DataFrame
print("\nClassification Report:\n")
display(dt_cr_df)

"""**4. Random Forest Hyperparameter Tuning**
Common Hyperparameters:
* n_estimators: Number of trees in the forest.
* max_depth: Maximum depth of the tree
* min_samples_split: Minimum number of samples required to split a node.
"""

# Define the parameter grid for Random Forest
param_grid_rf = {
    'n_estimators': [10, 100, 200],
    'max_depth': [5, 10, 50],
    'min_samples_split': [2, 5, 10]
}




# Initialize the GridSearchCV for Random Forest
grid_rf = GridSearchCV(RandomForestClassifier(), param_grid_rf, cv=5)

# Train the model using Grid Search
grid_rf.fit(X_train, y_train)

# Best parameters from Grid Search
print("Best parameters for Random Forest:", grid_rf.best_params_)

# Evaluate the model with the best parameters
best_rf = grid_rf.best_estimator_
y_pred_rf = best_rf.predict(X_test)

# Accuracy 98.54%
rf_accuracy = accuracy_score(y_test, y_pred_rf) * 100
print("Random Forest Accuracy after tuning: {:.2f}%".format(rf_accuracy))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred_rf)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.title(f'Confusion Matrix for Random Forest')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

# Classification Report
rf_cr = classification_report(y_test, y_pred_rf, output_dict=True)
rf_cr_df = pd.DataFrame(rf_cr).transpose()  # Convert to DataFrame
print("\nClassification Report:\n")
display(rf_cr_df)

"""**5. k-Nearest Neighbors (k-NN) Hyperparameter Tuning**
Common Hyperparameters:
* n_neighbors: Number of neighbors to use.
* weights: Weight function used in prediction('uniform', 'distance').

"""

# Define the parameter grid for k-NN
param_grid_knn = {
    'n_neighbors': [2,5,7],
    'weights': ['uniform']
}

# Initialize the GridSearchCV for k-NN
grid_knn = GridSearchCV(KNeighborsClassifier(), param_grid_knn, cv=5)

# Train the model using Grid Search
grid_knn.fit(X_train, y_train)

# Best parameters from Grid Search
print("Best parameters for k-NN:", grid_knn.best_params_)

# Evaluate the model with the best parameters
best_knn = grid_knn.best_estimator_
y_pred_knn = best_knn.predict(X_test)

# Accuracy
knn_accuracy = accuracy_score(y_test, y_pred_knn) * 100
print("k-NN Accuracy after tuning: {:.2f}%".format(knn_accuracy))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred_knn)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.title(f'Confusion Matrix for KNN')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

# Classification Report
knn_cr = classification_report(y_test, y_pred_knn, output_dict=True)
knn_cr_df = pd.DataFrame(knn_cr).transpose()  # Convert to DataFrame
print("\nClassification Report:\n")
display(knn_cr_df)

"""****

**Deep_learning_Model**

 Multi-layer Perceptron (MLP): Definition: An MLP is a type of artificial neural network that consists of multiple layers of nodes (neurons). It includes an input layer, one or more hidden layers, and an output layer.
"""

# Define the MLP model
mlp_model = Sequential()

#hyperparameters tunning
mlp_model.add(Dense(68, activation='relu', input_shape=(X_train.shape[1],)))
mlp_model.add(Dense(34, activation='relu'))
mlp_model.add(Dense(1, activation='sigmoid'))  # For binary classification

# Compile the model
mlp_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Add EarlyStopping
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Train the model
mlp_model.fit(X_train, y_train, validation_split=0.2, epochs=100, batch_size=40, callbacks=[early_stopping])

# Evaluate the model
y_pred_mlp = (mlp_model.predict(X_test) > 0.5).astype("int32")
mlp_accuracy = accuracy_score(y_test, y_pred_mlp) * 100
print("MLP Accuracy: {:.2f}%".format(mlp_accuracy))